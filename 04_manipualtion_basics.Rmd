---
title: "Manipulation Basics"
author: "Chidi"
date: "12/4/2017"
output: html_document
---

```{r setup, include=FALSE, warning=FALSE, echo=TRUE, message=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  comment = "#>",
  collapse = TRUE,
  cache = TRUE)
```

#### Note: Answers to questions are what I think they are at the time of writing them. Would have to come back to check my aswers again. 

Some common data manipulation functions are `filter`, `select`, `mutate`, `group_by`, `summarise`, these are usually used when performing data manipulation.  

```{r include=TRUE, warning=FALSE, echo=TRUE, message=FALSE}
library(tidyverse)
library(nycflights13)
```

### Filter  

`filter()` allows us subset observations based on their values. The first argument is the name of the dataset, subsequest argument are the expressions for filtering the data frame. 

```{r}
filter(flights, month == 1, day == 1)
```

When comparing different floating numbers, use the `near` function. Take the following example  

```{r}
sqrt(2) ^ 2 == 2 # returns false, but should be true 
(1/49) * 49 == 1 # returns false too, but should be true
```
The above expressions returned false, but should have been true, this is because, computers use finite precision arithmetic, so every number is an approximation. So to avoid that, use the `near` function   

```{r}
near(sqrt(2) ^ 2, 2) # returns True
near(1/49 * 49, 1) # also returns true
```

Other filtering examples  

```{r}
filter(flights, month == 1 & day == 1)
filter(flights, month == 11 | month == 12) # is similar to the the following below
filter(flights, month %in% c(11, 12)) 
```

Also, we can simplify complicated subsetting using some basic equation rules (De Morgan's Law); 

```
!(x | y) is the same as (!x | !y)
!(x & y) is the same as (!x & !y)
```

So for example  
```{r}
filter(flights, !(arr_delay > 120 | dep_delay > 120)) 
# Or
filter(flights, arr_delay <= 120, dep_delay <= 120)
```

Note that expressions involving **NA** values are always **NA**, for example  

```{r}
x <- NA
y <- NA
x == y # evaluates to NA
4 == NA # returns NA too
```
This is because NA is like saying "we don't know", "Not available", so it could be something, but we don't know its value as it isn't available.  We can check for NA with the `is.na`.  `filter` only includes rows that evaluates to true on the given conditions and excludes False and NA results. If I want to include NA values, I'll have to explicitly ask for them. For example  

```{r}
df <- tibble(x = c(1, NA, 3))
filter(df, x > 1) # returns only 3
filter(df, x > 1 | is.na(x)) # returns NA and 3
```


### Exercises  

##### 1. Find all flights that
###### a. Had an arrival delay of two or more hours
###### b. Flew to Houston (IAH or HOU)
###### c. Were operated by United, American, and Delta
###### d. Departed in summer (July, August, and September)
###### e. Arrived more than two hours late, but didnâ€™t leave late
###### f. Were delayed by at least an hour, but made up over 30 minutes in flight
###### g. Departed between midnight and 6am (inclusive)  

Use `?flights` to get information on the data set, to at least know which variables are appropriate. For example, from there, I got to see that the `carrier` variable is the two letter code of airlines name, and the full names are found in the `airlines` dataset, this helped me answer question 1c.  

```{r cache=TRUE}
ans_a <- filter(flights, arr_delay >= 120)
ans_b <- filter(flights, dest %in% c("IAH", "HOU"))
# from the airlines data set, the code for the airlines in question 1c are UA, AA, and DL. 
ans_c <- filter(flights, carrier %in% c("UA", "AA", "DL"))

# Another way I can answer C would be the following
airlines_flights <- merge(airlines, flights) # this is a new dataframe with all unique variables in both datasets, from there I have the names in the question
ans_c <- filter(airlines_flights, grepl("American|Delta|United", name, ignore.case = TRUE))
ans_d <- filter(flights, month %in% c(7:9)) 
## I can also use between to do the above
ans_d <- filter(flights, between(month, 7, 9))
ans_e <- filter(flights, arr_delay > 120 & dep_delay <= 0)
ans_f <- filter(flights, dep_delay >= 60 & dep_delay - arr_delay > 30)

# time here is represented in 24hrs, so 6am == 6:00am is 600 here, 13:00 is 1300, etc
ans_g <- filter(flights, dep_time >= 2400 | dep_time <= 600)
flights_size = nrow(flights)
```

Based on the above, for flights away from NYC in 2013, **`r round((nrow(ans_a)/flights_size) * 100, 2)`%**  of those flights had an arrival delay of two or more hours. There were **`r nrow(ans_b)`** flights to Houston. Three airlines (United, American, and Delta) operated a total of **`r nrow(ans_c)`** flights from NYC, which was about **`r round((nrow(ans_c)/flights_size) * 100, 2)`%** of all the flights from NYC that year. 
**`r round((nrow(ans_d)/flights_size) * 100, 2)`%** of all flights were made during the summer that year. **`r nrow(ans_e)`** flights arrived over two hours late, but had no departure delay, why? And finally, about **`r round((nrow(ans_g)/flights_size) * 100, 2)`%** of the flights from NYC in 2013 were between midnight and 6am.  

##### 2. Another useful dplyr filtering helper is between(). What does it do? Can you use it to simplify the code needed to answer the previous challenges?  

Between is a shortcut for the condition `x >= left & x <= right`. I used it above as well to geth the result for question 1d (`ans_d`) above.  

##### 3. How many flights have a missing dep_time? What other variables are missing? What might these rows represent? 

```{r warning=FALSE}
missing_dep_time <- flights %>%
  filter(is.na(dep_time)) %>%
  count()

(variables_with_missing_names <- names(which(apply(flights, 2, function(x) any(is.na(x))))))
```

**`r missing_dep_time$n`** flights has missing departure time. 

##### 4. Why is NA ^ 0 not missing? Why is NA | TRUE not missing? Why is FALSE & NA not missing? Can you figure out the general rule? (NA * 0 is a tricky counterexample!)

```{r}
NA ^ 0 # I think because (mathematically), anything to the power of 0 is always 1
NA | TRUE # Could be because OR needs just one condition to be true to evaluate to true
FALSE & NA # Similar to the one above, AND would always evaluate to false given at least one false expression
NA * 0 # Could be because this expression is like saying "Something thats not available zero times", which should result to "something thats not available". Thats my logical answer for this one, may not be completely right. 
```


### Mutate  

Mutating data is about creating new columns from existing columns in the data set. With dplyr's `mutate()`, we can create new variables.  

```{r}
flights %>% 
  mutate(gain = arr_delay - dep_delay,
         hours = air_time / 60,
         speed = distance / air_time * 60,
         gains_per_hour = gain/hours)
```

The above mutate would append the newly created variables to the previous ones, but if I want to take the result of only the newly created variables, I'll use `transmute` instead of `mutate`.  

```{r}
flights %>% 
  transmute(gain = arr_delay - dep_delay,
         hours = air_time / 60,
         speed = distance / air_time * 60,
         gains_per_hour = gain/hours)
```

When creating new variables with mutate or transmute, the function should take be able to work on vectors and return a vector of the the same size. Arithmetic functions like +, -, *, /, etc are all vectorised, and can be used with aggregate functions, which is a vectorised operation, and would return a vector, eg `y / sum(y)`. Modular arithmetic, like integer division `%/%` and `%%` (remainder) are also vectorised, and can be useful as it can help us break integers into pieces. For example;

```{r}
flights %>%
  transmute(dep_time,
            hour = dep_time %/% 100,
            minutes = dep_time %% 100)
```

Logarithms are also very useful transformations for dealing with data of multiple orders of magintude. Using `log2` transformation was recommended in the book (R for Data science), given that they're easy to interprete. 

`lead` and `lag` functions are also useful functions as they allows us refer to leading or lagging values. They can be very useful functions when combined with `group_by`

```{r}
(x = 1:10)
lead(x)
lag(x)
x - lag(x)
x != lag(x)
lag(1:10, 5)
```

Other possible useful functions we might want to use includes cummulative and aggregate functions (like `cumsum`, `cumprod`, dplyr's `cummean`), logical comparisons, ranking (like `min_rank`, `row_number`, `dense_rank`, `percent_rank`, `ntile`, etc)